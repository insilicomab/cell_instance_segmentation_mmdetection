{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from pycocotools import mask as maskUtils\n",
    "from joblib import Parallel, delayed\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../inputs/train_val_gkfold_split.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(rle, img_w, img_h):\n",
    "    \n",
    "    ## transforming the string into an array of shape (2, N)\n",
    "    array = np.fromiter(rle.split(), dtype = np.uint)\n",
    "    array = array.reshape((-1,2)).T\n",
    "    array[0] = array[0] - 1\n",
    "    \n",
    "    ## decompressing the rle encoding (ie, turning [3, 1, 10, 2] into [3, 4, 10, 11, 12])\n",
    "    # for faster mask construction\n",
    "    starts, lenghts = array\n",
    "    mask_decompressed = np.concatenate([np.arange(s, s + l, dtype = np.uint) for s, l in zip(starts, lenghts)])\n",
    "\n",
    "    ## Building the binary mask\n",
    "    msk_img = np.zeros(img_w * img_h, dtype = np.uint8)\n",
    "    msk_img[mask_decompressed] = 1\n",
    "    msk_img = msk_img.reshape((img_h, img_w))\n",
    "    msk_img = np.asfortranarray(msk_img) ## This is important so pycocotools can handle this object\n",
    "    \n",
    "    return msk_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(idx, row, cat_ids):\n",
    "        mask = rle2mask(row['annotation'], row['width'], row['height']) # Binary mask\n",
    "        c_rle = maskUtils.encode(mask) # Encoding it back to rle (coco format)\n",
    "        c_rle['counts'] = c_rle['counts'].decode('utf-8') # converting from binary to utf-8\n",
    "        area = maskUtils.area(c_rle).item() # calculating the area\n",
    "        bbox = maskUtils.toBbox(c_rle).astype(int).tolist() # calculating the bboxes\n",
    "        annotation = {\n",
    "            'segmentation': c_rle,\n",
    "            'bbox': bbox,\n",
    "            'area': area,\n",
    "            'image_id':row['id'], \n",
    "            'category_id':cat_ids[row['cell_type']], \n",
    "            'iscrowd':0, \n",
    "            'id':idx\n",
    "        }\n",
    "        return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_structure(df, workers = 4):\n",
    "    \n",
    "    ## Building the header\n",
    "    cat_ids = {name:id+1 for id, name in enumerate(df.cell_type.unique())}    \n",
    "    cats =[{'name':name, 'id':id} for name,id in cat_ids.items()]\n",
    "    images = [{'id':id, 'width':row.width, 'height':row.height, 'file_name':f'train/{id}.png'} for id,row in df.groupby('id').agg('first').iterrows()]\n",
    "    \n",
    "    ## Building the annotations\n",
    "    annotations = Parallel(n_jobs=workers)(delayed(annotate)(idx, row, cat_ids) for idx, row in tqdm(df.iterrows(), total = len(df)))\n",
    "        \n",
    "    return {'categories':cats, 'images':images, 'annotations':annotations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coco_json(df, w_fold, save_dir):\n",
    "    train_sample = df[df[\"fold\"] != w_fold]\n",
    "    train_coco_json = coco_structure(train_sample)\n",
    "    \n",
    "    valid_sample = df[df[\"fold\"] == w_fold]\n",
    "    valid_coco_json = coco_structure(valid_sample)\n",
    "\n",
    "    with open(f'{save_dir}/annotations_train_f{str(w_fold)}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_coco_json, f, ensure_ascii=True, indent=4)\n",
    "    \n",
    "    with open(f'{save_dir}/annotations_valid_f{str(w_fold)}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_coco_json, f, ensure_ascii=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65fa1268c8d4f028c27394b013f4a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55c4cd722794aeaa22355c5fa038578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_coco_json(df, w_fold=0, save_dir=\"../inputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
